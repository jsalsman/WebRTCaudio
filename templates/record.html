<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>webrec: Record and Upload Audio</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- TODO: maybe try viewport-fit=cover for mobile -->
  <link rel="icon" href="/static/microphone.png">
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.7/dist/bundle.min.js"></script>
</head>
<body>
  <h2>Record and Upload Audio with Stop on Silence</h2>

  <div style="font-size: 150%;">
    <label><input type="checkbox" id="vad" checked> Stop</label> after:
    <label><input type="radio" name="sil_dur" value="1"> 1,</label>
    <label><input type="radio" name="sil_dur" value="2" checked> 2,</label> or
    <label><input type="radio" name="sil_dur" value="3"> 3 seconds</label>
    of silence.
  </div>

  <br>
  Audio level: <meter id="level" min="0" max="1" 
    low="0.1" high="0.7" value="0" style="width: 210px;"></meter>
    <span id="vadSpan"></span>
  <br><br>
  <span id="secs">00.0</span> of up to 60 seconds: <meter id="full" 
    min="0" max="60" high="55" value="0" style="width: 180px;"></meter>
  <br><br>

  <button id="start" style="font-size: 130%;" disabled>Initializing...</button>
  &nbsp;
  <span id="safari" style="display: none;"><h3>Apple Safari users <a
    href="https://support.apple.com/guide/mac-help/control-access-to-the-microphone-on-mac-mchla1b1e1fe/mac"
    >please see here.</a></h3></span>
  &nbsp;
  <button id="startOver" style="font-size: 130%; display: none;"
    >Start Over</button>

  <script>
    var context, gotContext = false;  // audioContext
    var stream, recorder = null, isRecording = false;
    var vad, stopped_speaking_timeout = null;  // VAD timeout

    window.onload = async function() {  
      // Make sure the browser has audio
      if (!window.audioContext) {
        try {
          window.AudioContext = 
            window.AudioContext || window.webkitAudioContext;
          context = new AudioContext({ sampleRate: 16000 });
          if (context.state === 'running') {
            gotContext = true;
          } else {            
            // AudioContext is suspended, needs a click
            document.getElementById('start').textContent = 'Detect Audio Levels';
            document.getElementById('start').disabled = false;
          }
        } catch (e) {
          document.getElementById('start').style.display = 'none';
          alert('Web audio is not supported on this browser.');
        }
      } else {
        context = new AudioContext({ sampleRate: 16000 });
        if (context.state === 'running') {
          gotContext = true;
        } else {
          // needs a click
          document.getElementById('start').textContent = 'Sense Audio Levels';
          document.getElementById('start').disabled = false;
        }
      }
      
      // Check if microphone permissions already work
      navigator.mediaDevices.enumerateDevices().then(async devices => {
        if (devices.some(device => device.kind === 'audioinput' && device.label)) {
          // The user has granted microphone access
          if (context.state === 'running') {
            await initRecorder();
          }
        } else {
          // Microphone access not granted or no microphone available
          if (/^((?!chrome|android).)*safari/i.test(navigator.userAgent)) {
            // Apple Safari needs special permissions
            document.getElementById('safari').style.display = 'inline';
          }
          document.getElementById('start').textContent = 'Allow Microphone Use';
          document.getElementById('start').disabled = false;
        }
      });
      
      document.getElementById('start').addEventListener('click', async () => {
        if (!recorder) {
          document.getElementById('start').disabled = true;
          document.getElementById('start').textContent = 'Initializing...';
          context.resume();
          await initRecorder();
        } else if (!isRecording) {
          startRecording();
        } else {
          stopRecording();
        }
      });
      
      document.getElementById('startOver').onclick = function() {
        if (recorder && isRecording) { 
          // setRecording: true will reset recorded samples to zero
          recorder.port.postMessage({ message: 'UPDATE_RECORDING_STATE', 
                         setRecording: true });
          clearTimeout(stopped_speaking_timeout);
        }
      }
    }

    async function initRecorder() {
      try {
        stream = await navigator.mediaDevices.getUserMedia(
          { audio: {
            echoCancellation: false,
            autoGainControl: false,   // TODO: try?
            noiseSuppression: false,  // try!
            latency: 0},              // ???
           video: false });
        
        const micSourceNode = new MediaStreamAudioSourceNode(context,
            {mediaStream: stream});
        
        await context.audioWorklet.addModule('/static/recording-processor.js');
        recorder = new AudioWorkletNode(context, 'recording-processor',
          { processorOptions: {
            numberOfChannels: 1,
            sampleRate: 16000,
            maxFrameCount: 16000 * 60 // one minute
          }});
  
        await micSourceNode.connect(recorder);
  
        recorder.port.onmessage = event => {
          
          if (event.data.message === 'SHARE_RECORDING_BUFFER') { 
            // Recording ended, upload file
            let length = event.data.recordingLength;
            console.log('Seconds Recorded: ' + length / 16000);

            let buffer = event.data.buffer[0];
            let pcmData = new Uint8Array(length * 2);
            for (let index = 0; index < length; ++index) {
              let sample = buffer[index];
              sample = sample * 32768.0;
              sample = Math.max(-32768, Math.min(32767, sample));
              pcmData[index * 2] = sample & 255; // low byte, little endian
              pcmData[index * 2 + 1] = (sample >> 8) & 255; // high byte
            }
  
            let formData = new FormData();
            let blob = new Blob([pcmData], { type: 'audio/l16' });
            formData.append('audio', blob, 'audio.raw');            
            fetch('/upload-audio', {
              method: 'POST',
              body: formData
            }).then(response => {
              if (response.ok) {
                window.location.href = response.url;
              }
            }).catch(error => {
              alert('Upload error:' + error);
            });
            
          } else if (event.data.message === 'MAX_RECORDING_LENGTH_REACHED') {
            stopRecording();
            
          } else if (event.data.message === 'UPDATE_RECORDING_LENGTH') {
            //console.log('Samples so far: ' + event.data.recordingLength);
            let seconds = event.data.recordingLength / 16000
            document.getElementById('full').value = seconds.toFixed(2);
            document.getElementById('secs').textContent = 
              seconds.toFixed(1).padStart(4, '0');
            
          } else if (event.data.message === 'UPDATE_VISUALIZERS') {
            let expKx = Math.exp(15 * event.data.gain);
            document.getElementById('level').value = 
              ((expKx - 1) / (expKx + Math.E)).toFixed(2);
          }
        }
  
        // Voice Activity Detection: @ricky0123/vad-web
        // https://www.vad.ricky0123.com/docs/browser/
        const originalConsoleError = console.error; // TODO: omit in production
        console.error = () => {}; // supress console error messages from ort.js
        vad = await vad.MicVAD.new({
          additionalAudioConstraints: { audio: stream },
          onSpeechStart: () => {
            console.log('VAD: Speaking started');
            document.getElementById('vadSpan').textContent = 'Speech';
            document.getElementById('vadSpan').style.color = 'darkgreen';
            clearTimeout(stopped_speaking_timeout);
          },
          onSpeechEnd: (audio) => {
            console.log('VAD: Speaking stopped');
            document.getElementById('vadSpan').textContent = 'Silence';
            document.getElementById('vadSpan').style.color = 'darkgray';
            if (isRecording && document.getElementById('vad').checked) {
              silence_secs = document.querySelector('input[name="sil_dur"]:checked').value;
              stopped_speaking_timeout = setTimeout(stopRecording, silence_secs * 1000);
            } else {
              clearTimeout(stopped_speaking_timeout);
            }
          }
        });
        console.error = originalConsoleError; // TODO: omit in production
        vad.start();
        

        document.getElementById('safari').style.display = 'none';
        
        document.getElementById('start').textContent = 'Start Recording';
        document.getElementById('start').disabled = false;
  
      } catch (e) {
        console.error('Error initializing recorder:', e);
        document.getElementById('start').style.display = 'none';
        document.getElementById('startOver').style.display = 'none';
        alert('Error initializing recorder: ' + e);
      }
    }
    
    function startRecording() {
      recorder.port.postMessage({ message: 'UPDATE_RECORDING_STATE', 
                     setRecording: true });
      isRecording = true;
      
      document.getElementById('start').textContent = 'End Recording';
      document.getElementById('startOver').style.display = 'inline';
      document.getElementById('vadSpan').textContent = '';
    }

    function stopRecording() {
      clearTimeout(stopped_speaking_timeout);
      document.getElementById('start').disabled = true;
      document.getElementById('startOver').disabled = true;
      recorder.port.postMessage({ message: 'UPDATE_RECORDING_STATE', 
                     setRecording: false });
      isRecording = false;
    }
  </script>

  <br><br>
  Python Flask and JavaScript source code is
  <a href="https://replit.com/@jsalsman/webrec">on Replit</a>
  and <a href="https://github.com/jsalsman/webrec">GitHub.</a>
</body>
</html>
