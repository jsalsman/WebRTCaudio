<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Record Audio</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="/static/recbutton.jpg">
    <script src="/static/hark.js"></script>
</head>
<body>
    <h1>Record Audio with Stop on Silence</h1>
    
    <button id="start" style="font-size: 180%;">Start Recording</button>
    &nbsp;&nbsp;
    <button id="startOver" style="font-size: 180%; display: none;">Start Over</button>
    
    <br><br>
    <meter id="instant" high="0.25" max="1" value="0" style="width: 95%;"></meter>
    <br><br>
    
    <div style="font-size: 150%;">
        Stop after:
        <label><input type="radio" name="silence_duration" value="1">1,</label>
        <label><input type="radio" name="silence_duration" value="2" checked>2,</label> or
        <label><input type="radio" name="silence_duration" value="3">3 seconds</label>
        of silence.
    </div>

    <script>
        var silence_secs; // VAD silence delay
        var isRecording = false;
        var stopped_speaking_timeout;
        let recorder, recordingProperties; // AudioWorkletNode

        const instantMeter = document.querySelector('#instant meter');
        const instantValueDisplay = document.querySelector('#instant .value');

        class VUMeter {
            constructor(analyserNode, fftSize, fifoSize) {
                this.analyser_ = analyserNode;
                this.analyser_.fftSize = fftSize;

                // FIFO properties
                this.fifoSize_ = fifoSize;
                this.fifoData_ = new Float32Array(fifoSize);
                this.fifoHead_ = 0;
                this.fifoTail_ = 0;
                this.fifoCount_ = 0;

                this.dataArray_ = new Float32Array(this.analyser_.frequencyBinCount);
            }

            pushToFifo(value) {
                if (this.fifoCount_ === this.fifoSize_) {
                    this.fifoHead_ = (this.fifoHead_ + 1) % this.fifoSize_;
                    this.fifoCount_--;
                }
                this.fifoData_[this.fifoTail_] = value;
                this.fifoTail_ = (this.fifoTail_ + 1) % this.fifoSize_;
                this.fifoCount_++;
            }

            getMinValueFromFifo() {
                let minValue = Infinity;
                for (let i = 0; i < this.fifoCount_; i++) {
                    const index = (this.fifoHead_ + i) % this.fifoSize_;
                    if (this.fifoData_[index] < minValue) {
                        minValue = this.fifoData_[index];
                    }
                }
                return minValue;
            }

            updateMeter() {
                this.analyser_.getFloatTimeDomainData(this.dataArray_);
                const rootMeanSquare = this.calculateRMS(this.dataArray_);
                const decibel = 20 * Math.log10(rootMeanSquare);
                let absDecibel = Math.abs(decibel);

                this.pushToFifo(absDecibel);
                let minDecibel = this.getMinValueFromFifo();

                // Update the meter display
                instantMeter.value = instantValueDisplay.innerText = minDecibel.toFixed(2);
            }

            calculateRMS(inputArray) {
                let sumOfSquares = 0;
                for (let i = 0; i < inputArray.length; i++) {
                    sumOfSquares += inputArray[i] * inputArray[i];
                }
                let meanSquare = sumOfSquares / inputArray.length;
                return Math.sqrt(meanSquare);
            }
        }

        document.getElementById('start').onclick = function() {
            if (!isRecording) {
                startRecording();
            } else {
                stopRecording();
            }
        };

        async function startRecording() {
            if (!window.audioContext) {
                try {
                    window.AudioContext = window.AudioContext || window.webkitAudioContext;
                    window.audioContext = new AudioContext();
                } catch (e) {
                    alert('Web Audio API not supported.');
                    return;
                }
            }

            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
                window.stream = stream;
                
                const source = window.audioContext.createMediaStreamSource(stream);
                
                await window.audioContext.audioWorklet.addModule('/static/recording-processor.js');

                recordingProperties = {
                    numberOfChannels: 1,
                    sampleRate: 16000,
                    maxFrameCount: 16000 * 60 // one minute, adjust as needed
                };

                recorder = new AudioWorkletNode(
                    window.audioContext,
                    'recording-processor',
                    { processorOptions: recordingProperties }
                );

                recorder.port.onmessage = event => {
                    if (event.data.message === 'SHARE_RECORDING_BUFFER') {
                        createRecord(recordingProperties, event.data.recordingLength, window.audioContext.sampleRate, event.data.buffer);
                    }
                };

                recorder.port.postMessage({ message: 'UPDATE_RECORDING_STATE', setRecording: true });

                silence_secs = document.querySelector('input[name="silence_duration"]:checked').value;

                var speechEvents = hark(stream, {});
                speechEvents.on('speaking', function() {
                    clearTimeout(stopped_speaking_timeout);
                });

                speechEvents.on('stopped_speaking', stopRecordingAfterSilence);

                const analyserNode = window.audioContext.createAnalyser();
                source.connect(analyserNode);

                const vuMeter = new VUMeter(analyserNode, 2048, 10); // adjust fftSize and fifoSize as needed

                setInterval(() => {
                    vuMeter.updateMeter();
                }, 200); // Update every 200 milliseconds

                isRecording = true;
                document.getElementById('start').textContent = 'End Recording';
                document.getElementById('startOver').style.display = 'inline';
                var radioButtons = document.querySelectorAll('input[name="silence_duration"]');
                radioButtons.forEach(function(radioButton) {
                    radioButton.disabled = true;
                });
            } catch (e) {
                alert('Error initializing recording: ' + e.message);
            }
        }

        document.getElementById('startOver').onclick = function() {
            if (recorder && isRecording) {
                // Reset logic (if any)
                startRecording();
            }
        };

        function stopRecordingAfterSilence() {
            stopped_speaking_timeout = setTimeout(stopRecording, silence_secs * 1000);
        }

        function stopRecording() {
            if (recorder) {
                recorder.port.postMessage({ message: 'UPDATE_RECORDING_STATE', setRecording: false });
            }
            document.getElementById('start').disabled = true;
            document.getElementById('startOver').disabled = true;
            isRecording = false;
        }

        const createRecord = (recordingProperties, recordingLength, sampleRate, dataBuffer) => {
            const recordingBuffer = window.audioContext.createBuffer(
                recordingProperties.numberOfChannels,
                recordingLength,
                sampleRate);

            recordingBuffer.copyToChannel(dataBuffer[0], 0, 0);

            // Convert the audio buffer to a WAV blob
            bufferToWav(recordingBuffer).then(blob => {
                sendAudioToServer(blob);
            });
        };

        function bufferToWav(audioBuffer) {
        return new Promise((resolve, reject) => {
            const bitsPerSample = 16;
            const bytesPerSample = bitsPerSample / 8;
            const frameLength = audioBuffer.length;
            const numberOfChannels = audioBuffer.numberOfChannels;
            const sampleRate = audioBuffer.sampleRate;
            const byteRate = sampleRate * numberOfChannels * bytesPerSample;
            const blockAlign = numberOfChannels * bytesPerSample;
            const wavDataByteLength = frameLength * numberOfChannels * bytesPerSample;
            const headerByteLength = 44;
            const totalLength = headerByteLength + wavDataByteLength;

            const waveFileData = new Uint8Array(totalLength);
            const subChunk1Size = 16;
            const subChunk2Size = wavDataByteLength;
            const chunkSize = 4 + (8 + subChunk1Size) + (8 + subChunk2Size);

            function writeString(string, array, offset) {
                for (let i = 0; i < string.length; ++i) {
                    array[offset + i] = string.charCodeAt(i);
                }
            }

            function writeInt16(num, array, offset) {
                num = Math.floor(num);
                array[offset + 0] = num & 255; // byte 1
                array[offset + 1] = (num >> 8) & 255; // byte 2
            }

            function writeInt32(num, array, offset) {
                num = Math.floor(num);
                array[offset + 0] = num & 255; // byte 1
                array[offset + 1] = (num >> 8) & 255; // byte 2
                array[offset + 2] = (num >> 16) & 255; // byte 3
                array[offset + 3] = (num >> 24) & 255; // byte 4
            }

            // WAV file header
            writeString('RIFF', waveFileData, 0);
            writeInt32(chunkSize, waveFileData, 4);
            writeString('WAVE', waveFileData, 8);
            writeString('fmt ', waveFileData, 12);
            writeInt32(subChunk1Size, waveFileData, 16);
            writeInt16(1, waveFileData, 20); // AudioFormat: PCM
            writeInt16(numberOfChannels, waveFileData, 22);
            writeInt32(sampleRate, waveFileData, 24);
            writeInt32(byteRate, waveFileData, 28);
            writeInt16(blockAlign, waveFileData, 32);
            writeInt32(bitsPerSample, waveFileData, 34);
            writeString('data', waveFileData, 36);
            writeInt32(subChunk2Size, waveFileData, 40);
    
            let offset = 44;
            for (let index = 0; index < frameLength; ++index) {
                for (let channel = 0; channel < numberOfChannels; ++channel) {
                    let sample = audioBuffer.getChannelData(channel)[index];
                    sample = sample * 32768.0;
                    sample = Math.max(-32768, Math.min(32767, sample));
                    writeInt16(sample, waveFileData, offset);
                    offset += 2;
                }
            }
    
            const wavBlob = new Blob([waveFileData], { type: 'audio/wave' });
            resolve(wavBlob);
            });
        }
        
        function sendAudioToServer(blob) {
            var formData = new FormData();
            formData.append('audio', blob, 'audio.wav');
            fetch('/upload-audio', {
                method: 'POST',
                body: formData
            }).then(response => {
                if (response.ok) {
                    window.location.href = response.url;
                }
            });
        }
    </script>
    
    <br>
    Python Flask and JavaScript source code is
    <a href="https://replit.com/@jsalsman/WebRTCaudio">on Replit</a>
    and <a href="https://github.com/jsalsman/WebRTCaudio">GitHub.</a>
</body>
</html>
